{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JustinGaj/verizon-1a-project-falcon/blob/main/14k_model_run.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install roboflow"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pq3Tev720G3X",
        "outputId": "03997d60-27b1-4460-deda-044581d27882"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting roboflow\n",
            "  Downloading roboflow-1.2.11-py3-none-any.whl.metadata (9.7 kB)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from roboflow) (2025.11.12)\n",
            "Collecting idna==3.7 (from roboflow)\n",
            "  Downloading idna-3.7-py3-none-any.whl.metadata (9.9 kB)\n",
            "Requirement already satisfied: cycler in /usr/local/lib/python3.12/dist-packages (from roboflow) (0.12.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from roboflow) (1.4.9)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from roboflow) (3.10.0)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.12/dist-packages (from roboflow) (2.0.2)\n",
            "Collecting opencv-python-headless==4.10.0.84 (from roboflow)\n",
            "  Downloading opencv_python_headless-4.10.0.84-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
            "Requirement already satisfied: Pillow>=7.1.2 in /usr/local/lib/python3.12/dist-packages (from roboflow) (11.3.0)\n",
            "Collecting pi-heif<2 (from roboflow)\n",
            "  Downloading pi_heif-1.1.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (6.5 kB)\n",
            "Collecting pillow-avif-plugin<2 (from roboflow)\n",
            "  Downloading pillow_avif_plugin-1.5.2-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (2.1 kB)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.12/dist-packages (from roboflow) (2.9.0.post0)\n",
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.12/dist-packages (from roboflow) (1.2.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from roboflow) (2.32.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.12/dist-packages (from roboflow) (1.17.0)\n",
            "Requirement already satisfied: urllib3>=1.26.6 in /usr/local/lib/python3.12/dist-packages (from roboflow) (2.5.0)\n",
            "Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.12/dist-packages (from roboflow) (4.67.1)\n",
            "Requirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.12/dist-packages (from roboflow) (6.0.3)\n",
            "Requirement already satisfied: requests-toolbelt in /usr/local/lib/python3.12/dist-packages (from roboflow) (1.0.0)\n",
            "Collecting filetype (from roboflow)\n",
            "  Downloading filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->roboflow) (1.3.3)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->roboflow) (4.60.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->roboflow) (25.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->roboflow) (3.2.5)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->roboflow) (3.4.4)\n",
            "Downloading roboflow-1.2.11-py3-none-any.whl (89 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.9/89.9 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading idna-3.7-py3-none-any.whl (66 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.8/66.8 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opencv_python_headless-4.10.0.84-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (49.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.9/49.9 MB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pi_heif-1.1.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (1.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m15.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pillow_avif_plugin-1.5.2-cp312-cp312-manylinux_2_28_x86_64.whl (4.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.2/4.2 MB\u001b[0m \u001b[31m40.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
            "Installing collected packages: pillow-avif-plugin, filetype, pi-heif, opencv-python-headless, idna, roboflow\n",
            "  Attempting uninstall: opencv-python-headless\n",
            "    Found existing installation: opencv-python-headless 4.12.0.88\n",
            "    Uninstalling opencv-python-headless-4.12.0.88:\n",
            "      Successfully uninstalled opencv-python-headless-4.12.0.88\n",
            "  Attempting uninstall: idna\n",
            "    Found existing installation: idna 3.11\n",
            "    Uninstalling idna-3.11:\n",
            "      Successfully uninstalled idna-3.11\n",
            "Successfully installed filetype-1.2.0 idna-3.7 opencv-python-headless-4.10.0.84 pi-heif-1.1.1 pillow-avif-plugin-1.5.2 roboflow-1.2.11\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from roboflow import Roboflow\n",
        "\n",
        "import os\n",
        "import shutil\n",
        "import yaml\n",
        "from pathlib import Path\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms, models\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "kiUjLIgX0BIp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#utils\n",
        "\n",
        "class CellTowerDataset(Dataset):\n",
        "    \"\"\"Dataset for cell tower classification\"\"\"\n",
        "    def __init__(self, image_paths, labels, transform=None):\n",
        "        self.image_paths = image_paths\n",
        "        self.labels = labels\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = self.image_paths[idx]\n",
        "        image = Image.open(img_path).convert('RGB')\n",
        "        label = self.labels[idx]\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, label\n",
        "\n",
        "def parse_yolo_labels(label_path, cell_class_id, non_cell_class_ids):\n",
        "    \"\"\"Parse YOLO format labels to check if cell tower exists\"\"\"\n",
        "    if not os.path.exists(label_path):\n",
        "        return None\n",
        "\n",
        "    with open(label_path, 'r') as f:\n",
        "        lines = f.readlines()\n",
        "\n",
        "    if not lines:\n",
        "        return None\n",
        "\n",
        "    # Check ALL annotations in the file\n",
        "    has_cell_tower = False\n",
        "    has_non_cell = False\n",
        "    all_class_ids = []\n",
        "\n",
        "    for line in lines:\n",
        "        parts = line.strip().split()\n",
        "        if parts:\n",
        "            class_id = int(parts[0])\n",
        "            all_class_ids.append(class_id)\n",
        "            if class_id == cell_class_id:\n",
        "                has_cell_tower = True\n",
        "            if class_id in non_cell_class_ids:\n",
        "                has_non_cell = True\n",
        "\n",
        "    # Priority: cell tower > non-cell > other\n",
        "    if has_cell_tower:\n",
        "        return 'cell'\n",
        "    elif has_non_cell:\n",
        "        return 'non_cell'\n",
        "    else:\n",
        "        return 'unlabeled'\n",
        "\n",
        "def inspect_labels(data_dir, num_samples=10):\n",
        "    \"\"\"Inspect a few label files to see what's inside\"\"\"\n",
        "    train_labels_dir = os.path.join(data_dir, 'train', 'labels')\n",
        "\n",
        "    if not os.path.exists(train_labels_dir):\n",
        "        print(f\"Labels directory not found: {train_labels_dir}\")\n",
        "        return\n",
        "\n",
        "    label_files = [f for f in os.listdir(train_labels_dir) if f.endswith('.txt')][:num_samples]\n",
        "\n",
        "    print(f\"\\n=== INSPECTING {num_samples} LABEL FILES ===\")\n",
        "    for label_file in label_files:\n",
        "        label_path = os.path.join(train_labels_dir, label_file)\n",
        "        print(f\"\\nFile: {label_file}\")\n",
        "        with open(label_path, 'r') as f:\n",
        "            content = f.read()\n",
        "            if content.strip():\n",
        "                print(f\"Content: {content.strip()}\")\n",
        "            else:\n",
        "                print(\"Content: EMPTY\")\n",
        "\n",
        "def filter_dataset(data_dir, class_names):\n",
        "    \"\"\"\n",
        "    Filter dataset:\n",
        "    - TRAIN: Only use labeled images (cell=1, non/pow=0) for training\n",
        "    - VALID/TEST: Keep ALL images for prediction (will be labeled by model)\n",
        "\n",
        "    Args:\n",
        "        data_dir: Root directory of the dataset (should contain train/valid/test)\n",
        "        class_names: Dictionary mapping class IDs to names\n",
        "\n",
        "    Returns:\n",
        "        Training data and unlabeled validation/test data\n",
        "    \"\"\"\n",
        "    cell_class_id = None\n",
        "    non_cell_class_ids = []\n",
        "\n",
        "    # Find class IDs\n",
        "    for class_id, name in class_names.items():\n",
        "        if name.lower() == 'cell':\n",
        "            cell_class_id = class_id\n",
        "        elif name.lower() in ['non', 'pow']:\n",
        "            non_cell_class_ids.append(class_id)\n",
        "\n",
        "    print(f\"Cell tower class ID: {cell_class_id}\")\n",
        "    print(f\"Non-cell tower class IDs: {non_cell_class_ids}\")\n",
        "\n",
        "    # Training data (labeled only)\n",
        "    train_data = {'images': [], 'labels': []}\n",
        "\n",
        "    # Unlabeled data from train (other classes)\n",
        "    train_unlabeled = []\n",
        "\n",
        "    # All validation and test images (to be predicted)\n",
        "    valid_images = []\n",
        "    test_images = []\n",
        "\n",
        "    # Debugging counters\n",
        "    debug_stats = {\n",
        "        'train': {'total': 0, 'cell': 0, 'non_cell': 0, 'unlabeled': 0},\n",
        "        'valid': {'total': 0},\n",
        "        'test': {'total': 0}\n",
        "    }\n",
        "\n",
        "    # Process TRAIN split - filter for labeled data only\n",
        "    images_dir = os.path.join(data_dir, 'train', 'images')\n",
        "    labels_dir = os.path.join(data_dir, 'train', 'labels')\n",
        "\n",
        "    if os.path.exists(images_dir):\n",
        "        for img_file in os.listdir(images_dir):\n",
        "            if not img_file.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
        "                continue\n",
        "\n",
        "            debug_stats['train']['total'] += 1\n",
        "\n",
        "            img_path = os.path.join(images_dir, img_file)\n",
        "            label_file = os.path.splitext(img_file)[0] + '.txt'\n",
        "            label_path = os.path.join(labels_dir, label_file)\n",
        "\n",
        "            label_type = parse_yolo_labels(label_path, cell_class_id, non_cell_class_ids)\n",
        "\n",
        "            if label_type == 'cell':\n",
        "                debug_stats['train']['cell'] += 1\n",
        "                train_data['images'].append(img_path)\n",
        "                train_data['labels'].append(1)  # Has cell tower\n",
        "            elif label_type == 'non_cell':\n",
        "                debug_stats['train']['non_cell'] += 1\n",
        "                train_data['images'].append(img_path)\n",
        "                train_data['labels'].append(0)  # No cell tower\n",
        "            else:\n",
        "                debug_stats['train']['unlabeled'] += 1\n",
        "                train_unlabeled.append(img_path)\n",
        "\n",
        "    # Process VALID split - keep ALL images for prediction\n",
        "    valid_images_dir = os.path.join(data_dir, 'valid', 'images')\n",
        "    if os.path.exists(valid_images_dir):\n",
        "        for img_file in os.listdir(valid_images_dir):\n",
        "            if img_file.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
        "                debug_stats['valid']['total'] += 1\n",
        "                valid_images.append(os.path.join(valid_images_dir, img_file))\n",
        "\n",
        "    # Process TEST split - keep ALL images for prediction\n",
        "    test_images_dir = os.path.join(data_dir, 'test', 'images')\n",
        "    if os.path.exists(test_images_dir):\n",
        "        for img_file in os.listdir(test_images_dir):\n",
        "            if img_file.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
        "                debug_stats['test']['total'] += 1\n",
        "                test_images.append(os.path.join(test_images_dir, img_file))\n",
        "\n",
        "    # Print detailed statistics\n",
        "    print(\"\\n=== DATASET STATISTICS ===\")\n",
        "    print(f\"\\nTRAIN (for training):\")\n",
        "    print(f\"  Total images: {debug_stats['train']['total']}\")\n",
        "    print(f\"  Cell tower images (label=1): {debug_stats['train']['cell']}\")\n",
        "    print(f\"  Non-cell tower images (label=0): {debug_stats['train']['non_cell']}\")\n",
        "    print(f\"  Unlabeled (other classes): {debug_stats['train']['unlabeled']}\")\n",
        "    print(f\"  → Training set size: {len(train_data['images'])}\")\n",
        "\n",
        "    print(f\"\\nVALID (for prediction):\")\n",
        "    print(f\"  Total images: {debug_stats['valid']['total']}\")\n",
        "    print(f\"  → All will be predicted by model\")\n",
        "\n",
        "    print(f\"\\nTEST (for prediction):\")\n",
        "    print(f\"  Total images: {debug_stats['test']['total']}\")\n",
        "    print(f\"  → All will be predicted by model\")\n",
        "\n",
        "    return train_data, train_unlabeled, valid_images, test_images\n",
        "\n",
        "def get_transforms(is_training=True):\n",
        "    \"\"\"Get image transformations for training and validation\"\"\"\n",
        "    if is_training:\n",
        "        return transforms.Compose([\n",
        "            transforms.Resize((224, 224)),\n",
        "            transforms.RandomHorizontalFlip(),\n",
        "            transforms.RandomRotation(15),\n",
        "            transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                               std=[0.229, 0.224, 0.225])\n",
        "        ])\n",
        "    else:\n",
        "        return transforms.Compose([\n",
        "            transforms.Resize((224, 224)),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                               std=[0.229, 0.224, 0.225])\n",
        "        ])\n",
        "\n",
        "def create_model(num_classes=2):\n",
        "    \"\"\"Create a ResNet50 model for binary classification\"\"\"\n",
        "    model = models.resnet50(pretrained=True)\n",
        "\n",
        "    # Freeze early layers\n",
        "    for param in list(model.parameters())[:-15]:\n",
        "        param.requires_grad = False\n",
        "\n",
        "    # Replace final layer\n",
        "    num_features = model.fc.in_features\n",
        "    model.fc = nn.Sequential(\n",
        "        nn.Dropout(0.5),\n",
        "        nn.Linear(num_features, 256),\n",
        "        nn.ReLU(),\n",
        "        nn.Dropout(0.3),\n",
        "        nn.Linear(256, num_classes)\n",
        "    )\n",
        "\n",
        "    return model\n",
        "\n",
        "def train_model(model, train_loader, val_loader, num_epochs=20, device='cuda'):\n",
        "    \"\"\"Train the classification model\"\"\"\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min',\n",
        "                                                       factor=0.5, patience=3)\n",
        "\n",
        "    model = model.to(device)\n",
        "    best_val_acc = 0.0\n",
        "    has_validation = len(val_loader.dataset) > 0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        # Training phase\n",
        "        model.train()\n",
        "        train_loss = 0.0\n",
        "        train_preds = []\n",
        "        train_labels = []\n",
        "\n",
        "        pbar = tqdm(train_loader, desc=f'Epoch {epoch+1}/{num_epochs} [Train]')\n",
        "        for images, labels in pbar:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            train_loss += loss.item()\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            train_preds.extend(preds.cpu().numpy())\n",
        "            train_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "            pbar.set_postfix({'loss': loss.item()})\n",
        "\n",
        "        train_loss /= len(train_loader)\n",
        "        train_acc = accuracy_score(train_labels, train_preds)\n",
        "\n",
        "        print(f'\\nEpoch {epoch+1}/{num_epochs}')\n",
        "        print(f'Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}')\n",
        "\n",
        "        # Validation phase\n",
        "        if has_validation:\n",
        "            model.eval()\n",
        "            val_loss = 0.0\n",
        "            val_preds = []\n",
        "            val_labels = []\n",
        "\n",
        "            with torch.no_grad():\n",
        "                for images, labels in tqdm(val_loader, desc=f'Epoch {epoch+1}/{num_epochs} [Val]'):\n",
        "                    images, labels = images.to(device), labels.to(device)\n",
        "                    outputs = model(images)\n",
        "                    loss = criterion(outputs, labels)\n",
        "\n",
        "                    val_loss += loss.item()\n",
        "                    _, preds = torch.max(outputs, 1)\n",
        "                    val_preds.extend(preds.cpu().numpy())\n",
        "                    val_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "            val_loss /= len(val_loader)\n",
        "            val_acc = accuracy_score(val_labels, val_preds)\n",
        "\n",
        "            scheduler.step(val_loss)\n",
        "            print(f'Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}')\n",
        "\n",
        "            # Save best model\n",
        "            if val_acc > best_val_acc:\n",
        "                best_val_acc = val_acc\n",
        "                torch.save(model.state_dict(), 'best_cell_tower_model.pth')\n",
        "                print(f'Best model saved with validation accuracy: {best_val_acc:.4f}')\n",
        "        else:\n",
        "            # Save model periodically when no validation\n",
        "            torch.save(model.state_dict(), 'best_cell_tower_model.pth')\n",
        "            print('Model saved (no validation set)')\n",
        "\n",
        "    return model\n",
        "\n",
        "def predict_unlabeled(model, image_paths, device='cuda', batch_size=32):\n",
        "    \"\"\"Predict labels for unlabeled images\"\"\"\n",
        "    transform = get_transforms(is_training=False)\n",
        "\n",
        "    # Create dataset without labels\n",
        "    class UnlabeledDataset(Dataset):\n",
        "        def __init__(self, image_paths, transform):\n",
        "            self.image_paths = image_paths\n",
        "            self.transform = transform\n",
        "\n",
        "        def __len__(self):\n",
        "            return len(self.image_paths)\n",
        "\n",
        "        def __getitem__(self, idx):\n",
        "            img_path = self.image_paths[idx]\n",
        "            image = Image.open(img_path).convert('RGB')\n",
        "            if self.transform:\n",
        "                image = self.transform(image)\n",
        "            return image, img_path\n",
        "\n",
        "    dataset = UnlabeledDataset(image_paths, transform)\n",
        "    loader = DataLoader(dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
        "\n",
        "    model.eval()\n",
        "    predictions = []\n",
        "    paths = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, img_paths in tqdm(loader, desc='Predicting images'):\n",
        "            images = images.to(device)\n",
        "            outputs = model(images)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            predictions.extend(preds.cpu().numpy())\n",
        "            paths.extend(img_paths)\n",
        "\n",
        "    return paths, predictions\n",
        "\n",
        "def remove_non_cell_tower_images(image_paths, predictions, split_name):\n",
        "    \"\"\"Remove images that don't contain cell towers\"\"\"\n",
        "    # Get the base directory\n",
        "    base_dir = os.path.dirname(os.path.dirname(image_paths[0]))\n",
        "    removed_dir = os.path.join(base_dir, f'removed_non_cell_towers_{split_name}')\n",
        "    os.makedirs(removed_dir, exist_ok=True)\n",
        "\n",
        "    removed_count = 0\n",
        "    kept_count = 0\n",
        "\n",
        "    for img_path, pred in zip(image_paths, predictions):\n",
        "        if pred == 0:  # No cell tower\n",
        "            # Move to removed directory\n",
        "            filename = os.path.basename(img_path)\n",
        "            dest_path = os.path.join(removed_dir, filename)\n",
        "            shutil.move(img_path, dest_path)\n",
        "\n",
        "            # Also remove corresponding label file if it exists\n",
        "            label_path = img_path.replace('/images/', '/labels/').replace('.jpg', '.txt').replace('.jpeg', '.txt').replace('.png', '.txt')\n",
        "            if os.path.exists(label_path):\n",
        "                label_dest = os.path.join(removed_dir, os.path.basename(label_path))\n",
        "                shutil.move(label_path, label_dest)\n",
        "\n",
        "            removed_count += 1\n",
        "        else:\n",
        "            kept_count += 1\n",
        "\n",
        "    print(f\"\\n{split_name.upper()} Cleanup:\")\n",
        "    print(f\"  Images kept (have cell towers): {kept_count}\")\n",
        "    print(f\"  Images removed (no cell towers): {removed_count}\")\n",
        "    print(f\"  Removed images saved to: {removed_dir}\")\n",
        "\n",
        "\n",
        "def clean_dataset_with_model(model_path, data_dir, device='cuda', batch_size=32):\n",
        "    \"\"\"\n",
        "    STANDALONE FUNCTION: Clean a dataset by removing non-cell tower images using a trained model.\n",
        "\n",
        "    This function can be used independently to clean any dataset with a pre-trained model.\n",
        "    It will:\n",
        "    1. Load the trained model from the given path\n",
        "    2. Scan through train/valid/test splits\n",
        "    3. Predict which images contain cell towers\n",
        "    4. Move non-cell tower images to separate folders\n",
        "\n",
        "    Args:\n",
        "        model_path (str): Path to the saved model weights (.pth file)\n",
        "        data_dir (str): Root directory of the dataset (should contain train/valid/test folders)\n",
        "        device (str): Device to run predictions on ('cuda' or 'cpu')\n",
        "        batch_size (int): Batch size for predictions\n",
        "\n",
        "    Returns:\n",
        "        dict: Statistics about the cleanup operation\n",
        "\n",
        "    Example usage:\n",
        "        >>> # Clean a new dataset using pre-trained weights\n",
        "        >>> stats = clean_dataset_with_model(\n",
        "        ...     model_path='best_cell_tower_model.pth',\n",
        "        ...     data_dir='/path/to/new/dataset',\n",
        "        ...     device='cuda',\n",
        "        ...     batch_size=32\n",
        "        ... )\n",
        "    \"\"\"\n",
        "    print('='*60)\n",
        "    print('DATASET CLEANUP WITH PRE-TRAINED MODEL')\n",
        "    print('='*60)\n",
        "    print(f'Model: {model_path}')\n",
        "    print(f'Dataset: {data_dir}')\n",
        "    print(f'Device: {device}')\n",
        "    print('='*60)\n",
        "\n",
        "    # Load the model\n",
        "    print('\\nLoading model...')\n",
        "    model = create_model(num_classes=2)\n",
        "    model.load_state_dict(torch.load(model_path, map_location=device))\n",
        "    model = model.to(device)\n",
        "    model.eval()\n",
        "    print('Model loaded successfully!')\n",
        "\n",
        "    # Statistics dictionary\n",
        "    stats = {\n",
        "        'train': {'total': 0, 'kept': 0, 'removed': 0},\n",
        "        'valid': {'total': 0, 'kept': 0, 'removed': 0},\n",
        "        'test': {'total': 0, 'kept': 0, 'removed': 0}\n",
        "    }\n",
        "\n",
        "    # Process each split\n",
        "    splits = ['train', 'valid', 'test']\n",
        "\n",
        "    for split in splits:\n",
        "        print(f'\\n{\"=\"*60}')\n",
        "        print(f'Processing {split.upper()} split')\n",
        "        print(f'{\"=\"*60}')\n",
        "\n",
        "        images_dir = os.path.join(data_dir, split, 'images')\n",
        "\n",
        "        if not os.path.exists(images_dir):\n",
        "            print(f'  ⚠ Directory not found: {images_dir}')\n",
        "            continue\n",
        "\n",
        "        # Collect all images\n",
        "        image_paths = []\n",
        "        for img_file in os.listdir(images_dir):\n",
        "            if img_file.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
        "                image_paths.append(os.path.join(images_dir, img_file))\n",
        "\n",
        "        if len(image_paths) == 0:\n",
        "            print(f'  ⚠ No images found in {split} split')\n",
        "            continue\n",
        "\n",
        "        stats[split]['total'] = len(image_paths)\n",
        "        print(f'  Found {len(image_paths)} images')\n",
        "\n",
        "        # Predict\n",
        "        print(f'  Predicting...')\n",
        "        paths, predictions = predict_unlabeled(model, image_paths, device=device, batch_size=batch_size)\n",
        "\n",
        "        # Count predictions\n",
        "        cell_count = sum(1 for p in predictions if p == 1)\n",
        "        no_cell_count = sum(1 for p in predictions if p == 0)\n",
        "        print(f'  - With cell towers: {cell_count}')\n",
        "        print(f'  - Without cell towers: {no_cell_count}')\n",
        "\n",
        "        # Remove non-cell tower images\n",
        "        print(f'  Cleaning up...')\n",
        "        remove_non_cell_tower_images(paths, predictions, split)\n",
        "\n",
        "        stats[split]['kept'] = cell_count\n",
        "        stats[split]['removed'] = no_cell_count\n",
        "\n",
        "    # Print summary\n",
        "    print('\\n' + '='*60)\n",
        "    print('CLEANUP SUMMARY')\n",
        "    print('='*60)\n",
        "    total_kept = sum(stats[split]['kept'] for split in splits)\n",
        "    total_removed = sum(stats[split]['removed'] for split in splits)\n",
        "    total_processed = sum(stats[split]['total'] for split in splits)\n",
        "\n",
        "    for split in splits:\n",
        "        if stats[split]['total'] > 0:\n",
        "            print(f\"\\n{split.upper()}:\")\n",
        "            print(f\"  Total: {stats[split]['total']}\")\n",
        "            print(f\"  Kept: {stats[split]['kept']}\")\n",
        "            print(f\"  Removed: {stats[split]['removed']}\")\n",
        "\n",
        "    print(f\"\\nOVERALL:\")\n",
        "    print(f\"  Total processed: {total_processed}\")\n",
        "    print(f\"  Total kept: {total_kept}\")\n",
        "    print(f\"  Total removed: {total_removed}\")\n",
        "    print(f\"  Retention rate: {100*total_kept/total_processed:.1f}%\" if total_processed > 0 else \"  N/A\")\n",
        "\n",
        "    print('\\n' + '='*60)\n",
        "    print('✓ CLEANUP COMPLETE!')\n",
        "    print('='*60)\n",
        "    print('\\nNon-cell tower images have been moved to separate folders.')\n",
        "    print('Your train/valid/test folders now contain only images with cell towers.')\n",
        "\n",
        "    return stats\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "NVqqXRIw8rAy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "    # Configuration\n",
        "    DATA_DIR = '/content/Bird-nest-dataset-1'\n",
        "    BATCH_SIZE = 32\n",
        "    NUM_EPOCHS = 20\n",
        "    DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "    print(f'Using device: {DEVICE}')\n",
        "\n",
        "    # Load dataset configuration\n",
        "    yaml_path = os.path.join(DATA_DIR, 'data.yaml')\n",
        "    with open(yaml_path, 'r') as f:\n",
        "        data_config = yaml.safe_load(f)\n",
        "\n",
        "    # Get class names\n",
        "    class_names = {i: name for i, name in enumerate(data_config['names'])}\n",
        "    print(f'Classes: {class_names}')\n",
        "\n",
        "    # Inspect labels\n",
        "    inspect_labels(DATA_DIR, num_samples=10)\n",
        "\n",
        "    # Filter dataset\n",
        "    print('\\nFiltering dataset...')\n",
        "    train_data, train_unlabeled, valid_images, test_images = filter_dataset(DATA_DIR, class_names)\n",
        "\n",
        "    # Create validation set from training data\n",
        "    print('\\nCreating train/validation split from labeled training data...')\n",
        "\n",
        "    all_train_images = train_data['images']\n",
        "    all_train_labels = train_data['labels']\n",
        "\n",
        "    total_size = len(all_train_images)\n",
        "    val_size = int(0.2 * total_size)\n",
        "    train_size = total_size - val_size\n",
        "\n",
        "    indices = np.random.permutation(total_size)\n",
        "    train_indices = indices[:train_size]\n",
        "    val_indices = indices[train_size:]\n",
        "\n",
        "    train_images = [all_train_images[i] for i in train_indices]\n",
        "    train_labels = [all_train_labels[i] for i in train_indices]\n",
        "    val_images_for_training = [all_train_images[i] for i in val_indices]\n",
        "    val_labels_for_training = [all_train_labels[i] for i in val_indices]\n",
        "\n",
        "    print(f'Split - train: {len(train_images)}, validation: {len(val_images_for_training)}')\n",
        "\n",
        "    # Create datasets\n",
        "    train_dataset = CellTowerDataset(\n",
        "        train_images,\n",
        "        train_labels,\n",
        "        transform=get_transforms(is_training=True)\n",
        "    )\n",
        "\n",
        "    val_dataset = CellTowerDataset(\n",
        "        val_images_for_training,\n",
        "        val_labels_for_training,\n",
        "        transform=get_transforms(is_training=False)\n",
        "    )\n",
        "\n",
        "    # Create data loaders\n",
        "    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE,\n",
        "                            shuffle=True, num_workers=2)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE,\n",
        "                          shuffle=False, num_workers=2)\n",
        "\n",
        "    # Create and train model\n",
        "    print('\\nCreating model...')\n",
        "    model = create_model(num_classes=2)\n",
        "\n",
        "    print('\\nTraining model...')\n",
        "    model = train_model(model, train_loader, val_loader,\n",
        "                       num_epochs=NUM_EPOCHS, device=DEVICE)\n",
        "\n",
        "    # Clean the dataset using the trained model\n",
        "    print('\\n\\nNow cleaning the dataset with the trained model...')\n",
        "    stats = clean_dataset_with_model(\n",
        "        model_path='best_cell_tower_model.pth',\n",
        "        data_dir=DATA_DIR,\n",
        "        device=DEVICE,\n",
        "        batch_size=BATCH_SIZE\n",
        "    )\n",
        "\n",
        "# if __name__ == '__main__':\n",
        "#     main()"
      ],
      "metadata": {
        "id": "ktPqvGVgeknX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rf = Roboflow(api_key=\"ta7eF8BgO0KGqSxF1rpZ\")\n",
        "project = rf.workspace(\"kalynb700\").project(\"bird-nest-dataset-kpvdq-gc2uo-upzvj\")\n",
        "dataset = project.version(1).download(\"yolov8\")\n",
        "\n",
        "\n",
        "DATA_DIR = dataset.location  # Roboflow sets this automatically\n",
        "\n",
        "splits = [\"train\", \"valid\", \"test\"]\n",
        "\n",
        "for split in splits:\n",
        "    img_dir = os.path.join(DATA_DIR, split, \"images\")\n",
        "    count = len([f for f in os.listdir(img_dir) if f.lower().endswith(('.jpg','.jpeg','.png'))])\n",
        "    print(f\"{split} images: {count}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gjr2DWax3HZV",
        "outputId": "08b6af4f-b619-40f3-b5d5-430c0f57bf74"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading Roboflow workspace...\n",
            "loading Roboflow project...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading Dataset Version Zip in Bird-nest-dataset-1 to yolov8:: 100%|██████████| 156526/156526 [00:10<00:00, 15094.13it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Extracting Dataset Version Zip to Bird-nest-dataset-1 in yolov8:: 100%|██████████| 1256/1256 [00:00<00:00, 1730.21it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train images: 499\n",
            "valid images: 64\n",
            "test images: 59\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rf = Roboflow(api_key=\"ta7eF8BgO0KGqSxF1rpZ\")\n",
        "project = rf.workspace(\"bird-nests-bhmvs\").project(\"bird-nest-dataset-kpvdq-gc2uo\")\n",
        "version = project.version(2)\n",
        "dataset = version.download(\"yolov8\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0m7nhjU-3eZL",
        "outputId": "c1669324-38c7-4976-afba-15aa1d0015d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading Roboflow workspace...\n",
            "loading Roboflow project...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading Dataset Version Zip in Bird-nest-dataset-2 to yolov8:: 100%|██████████| 1956954/1956954 [01:42<00:00, 19066.53it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Extracting Dataset Version Zip to Bird-nest-dataset-2 in yolov8:: 100%|██████████| 28592/28592 [00:12<00:00, 2268.85it/s] \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "DATA_DIR = dataset.location  # Roboflow sets this automatically\n",
        "\n",
        "splits = [\"train\", \"valid\", \"test\"]\n",
        "\n",
        "for split in splits:\n",
        "    img_dir = os.path.join(DATA_DIR, split, \"images\")\n",
        "    count = len([f for f in os.listdir(img_dir) if f.lower().endswith(('.jpg','.jpeg','.png'))])\n",
        "    print(f\"{split} images: {count}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iaEg_2K74Zup",
        "outputId": "4bf97210-5877-4cb1-e1e2-46f708ceb975"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train images: 13185\n",
            "valid images: 658\n",
            "test images: 447\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Add this at the end of your script instead\n",
        "if __name__ == '__main__':\n",
        "    # Clean a different dataset with already-trained model\n",
        "    clean_dataset_with_model(\n",
        "        data_dir='/content/Bird-nest-dataset-2',\n",
        "        model_path='/content/best_cell_tower_model (1).pth',\n",
        "        device='cuda'\n",
        "    )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 617
        },
        "id": "Ma1kIxpweNyn",
        "outputId": "750bbf1e-7755-4146-a93e-14459ca304e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "DATASET CLEANUP WITH PRE-TRAINED MODEL\n",
            "============================================================\n",
            "Model: /content/best_cell_tower_model (1).pth\n",
            "Dataset: /content/Bird-nest-dataset-2\n",
            "Device: cuda\n",
            "============================================================\n",
            "\n",
            "Loading model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 97.8M/97.8M [00:00<00:00, 121MB/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/best_cell_tower_model (1).pth'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-4114860702.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;31m# Clean a different dataset with already-trained model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     clean_dataset_with_model(\n\u001b[0m\u001b[1;32m      5\u001b[0m         \u001b[0mdata_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'/content/Bird-nest-dataset-2'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mmodel_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'/content/best_cell_tower_model (1).pth'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-3213630695.py\u001b[0m in \u001b[0;36mclean_dataset_with_model\u001b[0;34m(model_path, data_dir, device, batch_size)\u001b[0m\n\u001b[1;32m    408\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\nLoading model...'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_classes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 410\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    411\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    412\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1482\u001b[0m         \u001b[0mpickle_load_args\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"encoding\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1483\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1484\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1485\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_is_zipfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1486\u001b[0m             \u001b[0;31m# The zipfile reader is going to advance the current file position.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    757\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mFileLike\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0m_opener\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mIO\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbytes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    758\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_is_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 759\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    760\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    761\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m\"w\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    738\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_opener\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mIO\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbytes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    739\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPathLike\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 740\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    741\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    742\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/best_cell_tower_model (1).pth'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " model = create_model(num_classes=2)"
      ],
      "metadata": {
        "id": "Mr6vcfzb684Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')\n",
        "\n",
        "# --- 2. Set the path to your weights ---\n",
        "# Replace this with the EXACT path to your .pth file inside Drive\n",
        "# If your notebook is inside the same Drive folder, it should look like:\n",
        "weights_path = \"best_cell_tower_model.pth\"\n",
        "\n",
        "\n",
        "model.load_state_dict(torch.load(weights_path, map_location=\"cpu\"))\n",
        "model.eval()   # sets the model into inference mode"
      ],
      "metadata": {
        "id": "YzvnrTNg7NIg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load YAML\n",
        "yaml_path = os.path.join(DATA_DIR, \"data.yaml\")\n",
        "with open(yaml_path, 'r') as f:\n",
        "    data_config = yaml.safe_load(f)\n",
        "\n",
        "# Map class IDs to class names\n",
        "class_names = {i: name for i, name in enumerate(data_config['names'])}\n",
        "print(\"Classes:\", class_names)\n"
      ],
      "metadata": {
        "id": "h-XS73me9Uwf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data, train_unlabeled, valid_images, test_images = filter_dataset(DATA_DIR, class_names)\n"
      ],
      "metadata": {
        "id": "9Y7JRGKp9Wl6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_images = train_data['images']\n",
        "all_labels = train_data['labels']\n",
        "\n",
        "total_size = len(all_images)\n",
        "val_size = int(0.2 * total_size)\n",
        "train_size = total_size - val_size\n",
        "\n",
        "indices = np.random.permutation(total_size)\n",
        "train_idx = indices[:train_size]\n",
        "val_idx = indices[train_size:]\n",
        "\n",
        "train_images = [all_images[i] for i in train_idx]\n",
        "train_labels = [all_labels[i] for i in train_idx]\n",
        "val_images = [all_images[i] for i in val_idx]\n",
        "val_labels = [all_labels[i] for i in val_idx]\n",
        "\n",
        "print(\"Train:\", len(train_images))\n",
        "print(\"Val:\", len(val_images))\n"
      ],
      "metadata": {
        "id": "6YDWMp4b9Xw5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = CellTowerDataset(train_images, train_labels, transform=get_transforms(True))\n",
        "val_dataset   = CellTowerDataset(val_images, val_labels, transform=get_transforms(False))\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=2)\n",
        "val_loader   = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=2)\n"
      ],
      "metadata": {
        "id": "6KIymFWz9Zxf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(\"Device:\", device)\n",
        "\n",
        "model = create_model(num_classes=2)\n",
        "model = model.to(device)\n",
        "\n",
        "model = train_model(model, train_loader, val_loader, num_epochs=20, device=device)\n"
      ],
      "metadata": {
        "id": "LP-bZQT99b3a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import yaml\n",
        "\n",
        "def relabel_nest_only(data_dir):\n",
        "    \"\"\"\n",
        "    Standalone function to relabel nest classes in a dataset.\n",
        "    Use this to relabel nest classes without training or cleaning.\n",
        "\n",
        "    Args:\n",
        "        data_dir: Path to dataset directory (should contain train/valid/test folders)\n",
        "    \"\"\"\n",
        "    print(f'Relabeling nest classes in: {data_dir}')\n",
        "\n",
        "    # Load dataset configuration\n",
        "    yaml_path = os.path.join(data_dir, 'data.yaml')\n",
        "    if not os.path.exists(yaml_path):\n",
        "        print(f\"Warning: {yaml_path} not found. Using default nest class IDs (0-12)\")\n",
        "        nest_class_ids = list(range(0, 13))\n",
        "    else:\n",
        "        with open(yaml_path, 'r') as f:\n",
        "            data_config = yaml.safe_load(f)\n",
        "\n",
        "        class_names = {i: name for i, name in enumerate(data_config['names'])}\n",
        "        print(f'Classes found: {class_names}')\n",
        "\n",
        "        # Define nest classes as 0-12\n",
        "        nest_class_ids = list(range(0, 13))\n",
        "\n",
        "    print(f\"Nest class IDs to relabel: {nest_class_ids}\")\n",
        "\n",
        "    # Relabel all nest classes\n",
        "    print('\\n' + '='*60)\n",
        "    print('RELABELING NEST CLASSES (0-12) TO CLASS 0')\n",
        "    print('='*60)\n",
        "\n",
        "    total_relabeled = 0\n",
        "\n",
        "    for split in ['train', 'valid', 'test']:\n",
        "        labels_dir = os.path.join(data_dir, split, 'labels')\n",
        "\n",
        "        if not os.path.exists(labels_dir):\n",
        "            continue\n",
        "\n",
        "        print(f\"\\nProcessing {split.upper()} labels...\")\n",
        "        split_count = 0\n",
        "\n",
        "        for label_file in os.listdir(labels_dir):\n",
        "            if not label_file.endswith('.txt'):\n",
        "                continue\n",
        "\n",
        "            label_path = os.path.join(labels_dir, label_file)\n",
        "\n",
        "            # Read and check if relabeling is needed\n",
        "            with open(label_path, 'r') as f:\n",
        "                lines = f.readlines()\n",
        "\n",
        "            new_lines = []\n",
        "            modified = False\n",
        "\n",
        "            for line in lines:\n",
        "                parts = line.strip().split()\n",
        "                if parts:\n",
        "                    class_id = int(parts[0])\n",
        "\n",
        "                    # If this is a nest class (1-12), relabel it to 0\n",
        "                    if class_id in nest_class_ids and class_id != 0:\n",
        "                        parts[0] = '0'\n",
        "                        new_lines.append(' '.join(parts) + '\\n')\n",
        "                        modified = True\n",
        "                    else:\n",
        "                        new_lines.append(line)\n",
        "                else:\n",
        "                    new_lines.append(line)\n",
        "\n",
        "            # Write back if modified\n",
        "            if modified:\n",
        "                with open(label_path, 'w') as f:\n",
        "                    f.writelines(new_lines)\n",
        "                split_count += 1\n",
        "\n",
        "        total_relabeled += split_count\n",
        "        print(f\"  Relabeled {split_count} files\")\n",
        "\n",
        "    print(f\"\\nTotal files relabeled: {total_relabeled}\")\n",
        "    print(\"All nest classes (0-12) are now labeled as class 0 'nest'\")\n",
        "\n",
        "    print('\\n' + '='*60)\n",
        "    print('RELABELING COMPLETE!')\n",
        "    print('='*60)\n",
        "    print('All nest classes (0-12) are now unified as class 0 \"nest\".')\n",
        "\n",
        "\n",
        "# Usage:\n",
        "if __name__ == '__main__':\n",
        "    relabel_nest_only('/content/Bird-nest-dataset-1')"
      ],
      "metadata": {
        "id": "Whrnidfd_KzC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# relabel only\n",
        "if __name__ == '__main__':\n",
        "    # Just relabel nest classes\n",
        "    relabel_nest_only('/content/Bird-nest-dataset-1')"
      ],
      "metadata": {
        "id": "BqhRsnxylL_r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# downloads another dataset with cell towers without nests\n",
        "\n",
        "!pip install roboflow\n",
        "\n",
        "from roboflow import Roboflow\n",
        "rf = Roboflow(api_key=\"4Mn9fOlHRF3rOZiPGW7f\")\n",
        "project = rf.workspace(\"bird-nests-bhmvs\").project(\"cell-towers-4bysq\")\n",
        "version = project.version(2)\n",
        "dataset = version.download(\"yolov8\")"
      ],
      "metadata": {
        "id": "PC0hKqpqv06D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#combines two datasets\n",
        "# the first dataset contains images of nests in cell towers\n",
        "# the second dataset contains images of cell towers with no tests\n",
        "\n",
        "\n",
        "import os\n",
        "import shutil\n",
        "import yaml\n",
        "\n",
        "# Paths to your two datasets\n",
        "dataset1_path = '/content/Bird-nest-dataset-2'\n",
        "dataset2_path = '/content/cell-towers-2'\n",
        "output_path = 'combined_dataset'\n",
        "\n",
        "# Create combined dataset structure\n",
        "for split in ['train', 'valid', 'test']:\n",
        "    os.makedirs(f'{output_path}/{split}/images', exist_ok=True)\n",
        "    os.makedirs(f'{output_path}/{split}/labels', exist_ok=True)\n",
        "\n",
        "# Function to copy files\n",
        "def copy_dataset_files(source_dataset, destination):\n",
        "    for split in ['train', 'valid', 'test']:\n",
        "        # Copy images\n",
        "        source_images = f'{source_dataset}/{split}/images'\n",
        "        dest_images = f'{destination}/{split}/images'\n",
        "\n",
        "        if os.path.exists(source_images):\n",
        "            for file in os.listdir(source_images):\n",
        "                shutil.copy2(\n",
        "                    os.path.join(source_images, file),\n",
        "                    os.path.join(dest_images, file)\n",
        "                )\n",
        "\n",
        "        # Copy labels\n",
        "        source_labels = f'{source_dataset}/{split}/labels'\n",
        "        dest_labels = f'{destination}/{split}/labels'\n",
        "\n",
        "        if os.path.exists(source_labels):\n",
        "            for file in os.listdir(source_labels):\n",
        "                shutil.copy2(\n",
        "                    os.path.join(source_labels, file),\n",
        "                    os.path.join(dest_labels, file)\n",
        "                )\n",
        "\n",
        "# Load both yaml files\n",
        "with open(f'{dataset1_path}/data.yaml') as f:\n",
        "    data1 = yaml.safe_load(f)\n",
        "with open(f'{dataset2_path}/data.yaml') as f:\n",
        "    data2 = yaml.safe_load(f)\n",
        "\n",
        "# Combine class names and create mapping\n",
        "combined_classes = data1['names'].copy()\n",
        "class_mapping = {}\n",
        "\n",
        "for idx, class_name in enumerate(data2['names']):\n",
        "    if class_name not in combined_classes:\n",
        "        class_mapping[idx] = len(combined_classes)\n",
        "        combined_classes.append(class_name)\n",
        "    else:\n",
        "        class_mapping[idx] = combined_classes.index(class_name)\n",
        "\n",
        "print(f\"Dataset 1 classes: {data1['names']}\")\n",
        "print(f\"Dataset 2 classes: {data2['names']}\")\n",
        "print(f\"Combined classes: {combined_classes}\")\n",
        "print(f\"Class mapping for dataset 2: {class_mapping}\")\n",
        "\n",
        "# Copy dataset 1 files (no remapping needed)\n",
        "print(\"\\nCopying dataset 1...\")\n",
        "copy_dataset_files(dataset1_path, output_path)\n",
        "\n",
        "# Copy dataset 2 files\n",
        "print(\"Copying dataset 2...\")\n",
        "copy_dataset_files(dataset2_path, output_path)\n",
        "\n",
        "# Remap class IDs in dataset 2 labels if needed\n",
        "if class_mapping and any(k != v for k, v in class_mapping.items()):\n",
        "    print(\"Remapping class IDs in dataset 2 labels...\")\n",
        "\n",
        "    for split in ['train', 'valid', 'test']:\n",
        "        label_dir = f'{output_path}/{split}/labels'\n",
        "\n",
        "        if os.path.exists(label_dir):\n",
        "            for label_file in os.listdir(label_dir):\n",
        "                if label_file.endswith('.txt'):\n",
        "                    label_path = os.path.join(label_dir, label_file)\n",
        "\n",
        "                    with open(label_path, 'r') as f:\n",
        "                        lines = f.readlines()\n",
        "\n",
        "                    new_lines = []\n",
        "                    for line in lines:\n",
        "                        parts = line.strip().split()\n",
        "                        if parts:  # Skip empty lines\n",
        "                            old_class = int(parts[0])\n",
        "                            new_class = class_mapping.get(old_class, old_class)\n",
        "                            new_lines.append(f\"{new_class} {' '.join(parts[1:])}\\n\")\n",
        "\n",
        "                    with open(label_path, 'w') as f:\n",
        "                        f.writelines(new_lines)\n",
        "\n",
        "# Create combined data.yaml\n",
        "combined_yaml = {\n",
        "    'train': './train/images',\n",
        "    'val': './valid/images',\n",
        "    'test': './test/images',\n",
        "    'nc': len(combined_classes),\n",
        "    'names': combined_classes\n",
        "}\n",
        "\n",
        "with open(f'{output_path}/data.yaml', 'w') as f:\n",
        "    yaml.dump(combined_yaml, f, default_flow_style=False)\n",
        "\n",
        "print(f\"\\n✓ Combined dataset created at: {output_path}\")\n",
        "print(f\"✓ Total classes: {len(combined_classes)}\")"
      ],
      "metadata": {
        "id": "s2JK1uypuZps"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#zip the file to be imported into the nest detection model\n",
        "\n",
        "!ls /content/combined_dataset\n",
        "!zip -r tower_robo.zip /content/combined_dataset"
      ],
      "metadata": {
        "id": "lkzJ3r6Zop-v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#downloads the tower_robo zip file\n",
        "\n",
        "from google.colab import files\n",
        "files.download(\"tower_robo.zip\")\n"
      ],
      "metadata": {
        "id": "To9ryHXJrDBc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}